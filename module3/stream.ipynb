{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-19T07:39:10.277232400Z",
     "start_time": "2026-02-19T07:39:08.304511900Z"
    }
   },
   "source": [
    "import os\n",
    "from lib import getAIMessage\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "working_dir = Path().cwd().parent\n",
    "sys.path.insert(0, str(working_dir))\n",
    "\n",
    "env_path = Path().cwd().parent.joinpath(\"sample.env\")\n",
    "load_dotenv(override=True, dotenv_path=env_path)\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"../db/memory.db\", check_same_thread=False )\n",
    "memory = SqliteSaver(conn)\n",
    "mem_config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "10efc5a1b53943b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T07:39:11.371748400Z",
     "start_time": "2026-02-19T07:39:10.278232900Z"
    }
   },
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = os.getenv(\"GPT_MODEL\")\n",
    "llm = ChatOpenAI(model=model)\n",
    "\n",
    "class State(MessagesState):\n",
    "    pass\n",
    "\n",
    "def agent1(state: State):\n",
    "    return {\"messages\":[llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "def agent2(state: State):\n",
    "    return {\"messages\":[llm.invoke(state[\"messages\"])]}\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "94e3bced45063672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T07:39:12.135241700Z",
     "start_time": "2026-02-19T07:39:11.408802300Z"
    }
   },
   "source": [
    "from IPython.core.display import Image\n",
    "from langgraph.constants import START\n",
    "\n",
    "g = StateGraph(State)\n",
    "g.add_node(agent1)\n",
    "g.add_node(agent2)\n",
    "\n",
    "\n",
    "g.add_edge(START, \"agent1\")\n",
    "\n",
    "gr  = g.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(gr.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "44af2b7397943dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T07:39:13.760145300Z",
     "start_time": "2026-02-19T07:39:12.145147200Z"
    }
   },
   "source": [
    "msg = {\"messages\":[HumanMessage(content=\"Hello, I am Vj\")]}\n",
    "res =  gr.invoke(msg, config=mem_config)\n",
    "getAIMessage(res)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello again, Vj! How can I assist you today? If you're still interested in planning a trip or if you have something else in mind, just let me know!\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "d43d7f1b18ddb1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T07:39:14.655206400Z",
     "start_time": "2026-02-19T07:39:13.771586900Z"
    }
   },
   "source": [
    "msg1 = {\"messages\":[HumanMessage(content=\"Who am I?\")]}\n",
    "for chunk in gr.stream(msg1, config= mem_config, stream_mode=\"values\"):\n",
    "    #print(chunk)\n",
    "    for m in chunk[\"messages\"]:\n",
    "        m.pretty_print()"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'agent1'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m msg1 = {\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m:[HumanMessage(content=\u001B[33m\"\u001B[39m\u001B[33mWho am I?\u001B[39m\u001B[33m\"\u001B[39m)]}\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m gr.stream(msg1, config= mem_config, stream_mode=\u001B[33m\"\u001B[39m\u001B[33mvalues\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m      3\u001B[39m     \u001B[38;5;66;03m#print(chunk)\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[43mchunk\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43magent1\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m      5\u001B[39m         m.pretty_print()\n",
      "\u001B[31mKeyError\u001B[39m: 'agent1'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "681a25c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T07:39:32.394656500Z",
     "start_time": "2026-02-19T07:39:30.883025700Z"
    }
   },
   "source": [
    "# stream responses from the graph using existing `gr` and `msg`\n",
    "\n",
    "for chunk in gr.stream(msg1, config=mem_config, stream_mode=\"updates\"):\n",
    "    for node_name, node_data in chunk.items():\n",
    "        for m in node_data.get(\"messages\", []):\n",
    "            try:\n",
    "                m.pretty_print()\n",
    "            except Exception as e:\n",
    "                print(m)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "You are Vj! If there’s more you’d like to share about yourself or if you have specific questions or topics in mind, feel free to let me know!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T07:46:32.345360Z",
     "start_time": "2026-02-19T07:46:31.110566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "msg2 = {\"messages\":[HumanMessage(content=\"My last quesiton\")]}\n",
    "for chunk in gr.stream(msg2, config=mem_config, stream_mode=\"values\"):\n",
    "    # if chunk[\"messages\"]:\n",
    "    #     print(chunk[\"messages\"][-1].content)\n",
    "    for ch in chunk[\"messages\"]:\n",
    "        print(ch.content, end=\"\\n=============\\n\")"
   ],
   "id": "8bf403a8559c4baf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Vj\n",
      "=============\n",
      "Hello, Vj! How can I assist you today?\n",
      "=============\n",
      "Who am I?\n",
      "=============\n",
      "You're Vj! Beyond that, I don't have personal information about you. If you'd like to share more about yourself or if there's something specific you want to discuss, feel free to let me know!\n",
      "=============\n",
      "Who am I?\n",
      "=============\n",
      "Who am I?\n",
      "=============\n",
      "You are Vj! If you're looking for something more specific, such as your interests, experiences, or role in a certain context, please provide more details, and I'd be happy to help!\n",
      "=============\n",
      "You are Vj! If you're looking for deeper insights or information about yourself, please share a bit more about what you're seeking—whether it's related to your interests, hobbies, or any other area, I'm here to help!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I don’t have access to personal information about individuals unless it has been shared in the course of our conversation. I only know that you are Vj because you introduced yourself that way. If there’s something specific you’d like to discuss or ask about, feel free to let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I don’t know you personally; I can only interact based on the information you choose to share during our conversation. I only know you as Vj because that's how you introduced yourself. If there's anything specific you'd like me to understand or discuss, please let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I don’t have any personal information about you; I only know what you choose to share in our conversation. You've identified yourself as Vj, and that's all I have to go on. If you have any specific questions or topics you'd like to discuss, feel free to let me know!\n",
      "=============\n",
      "Plan a trip\n",
      "=============\n",
      "Sure! I’d be happy to help you plan a trip. To tailor it to your preferences, I need a bit more information:\n",
      "\n",
      "1. **Destination:** Where do you want to go?\n",
      "2. **Duration:** How long do you plan to stay?\n",
      "3. **Interests:** What activities are you interested in (e.g., adventure, relaxation, culture, food)?\n",
      "4. **Budget:** Do you have an approximate budget in mind?\n",
      "5. **Travel companions:** Will you be traveling alone or with others? If so, how many and what are their preferences?\n",
      "\n",
      "Once I have a better idea of what you're looking for, I can provide a more personalized trip plan!\n",
      "=============\n",
      "Hello, I am Vj\n",
      "=============\n",
      "Hello again, Vj! How can I assist you today? If you're still interested in planning a trip or if you have something else in mind, just let me know!\n",
      "=============\n",
      "Who am I?\n",
      "=============\n",
      "You are Vj! If there’s more you’d like to share about yourself or if you have specific questions or topics in mind, feel free to let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I only know you as Vj because that's how you've introduced yourself in our conversation. I don't have any personal information about you beyond what you've shared. If there's something specific you'd like me to assist you with, just let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I know you as Vj because that's how you introduced yourself in our chat. I don't have any additional information about you unless you choose to share more. If you have any questions or topics you'd like to discuss, feel free to let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I know you as Vj simply because you told me so. I don’t have any personal information about you beyond what you've provided in this conversation. If you have any questions or topics you'd like to discuss, feel free to share!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I only know you as Vj because that's the name you've chosen to share in our conversation. I don't have any personal information about you or your background. If there's something specific you'd like to talk about or ask, just let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I know you as Vj because you've introduced yourself that way. Beyond that, I don't have any personal information about you. My knowledge about you is limited to what you choose to share in our conversation. If you have more specific questions or topics you'd like to discuss, feel free to let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I know you as Vj because you've told me that in our conversation. I don't have any personal information beyond what you've shared, and I can't access any external information about you. If there's something specific you want to discuss or know, feel free to ask!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I know you as Vj because that’s how you introduced yourself in our conversation. I don’t have any additional information about you unless you've provided it. If you have specific questions or topics in mind, I’m here to help!\n",
      "=============\n",
      "My last quesiton\n",
      "=============\n",
      "Hello, I am Vj\n",
      "=============\n",
      "Hello, Vj! How can I assist you today?\n",
      "=============\n",
      "Who am I?\n",
      "=============\n",
      "You're Vj! Beyond that, I don't have personal information about you. If you'd like to share more about yourself or if there's something specific you want to discuss, feel free to let me know!\n",
      "=============\n",
      "Who am I?\n",
      "=============\n",
      "Who am I?\n",
      "=============\n",
      "You are Vj! If you're looking for something more specific, such as your interests, experiences, or role in a certain context, please provide more details, and I'd be happy to help!\n",
      "=============\n",
      "You are Vj! If you're looking for deeper insights or information about yourself, please share a bit more about what you're seeking—whether it's related to your interests, hobbies, or any other area, I'm here to help!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I don’t have access to personal information about individuals unless it has been shared in the course of our conversation. I only know that you are Vj because you introduced yourself that way. If there’s something specific you’d like to discuss or ask about, feel free to let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I don’t know you personally; I can only interact based on the information you choose to share during our conversation. I only know you as Vj because that's how you introduced yourself. If there's anything specific you'd like me to understand or discuss, please let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I don’t have any personal information about you; I only know what you choose to share in our conversation. You've identified yourself as Vj, and that's all I have to go on. If you have any specific questions or topics you'd like to discuss, feel free to let me know!\n",
      "=============\n",
      "Plan a trip\n",
      "=============\n",
      "Sure! I’d be happy to help you plan a trip. To tailor it to your preferences, I need a bit more information:\n",
      "\n",
      "1. **Destination:** Where do you want to go?\n",
      "2. **Duration:** How long do you plan to stay?\n",
      "3. **Interests:** What activities are you interested in (e.g., adventure, relaxation, culture, food)?\n",
      "4. **Budget:** Do you have an approximate budget in mind?\n",
      "5. **Travel companions:** Will you be traveling alone or with others? If so, how many and what are their preferences?\n",
      "\n",
      "Once I have a better idea of what you're looking for, I can provide a more personalized trip plan!\n",
      "=============\n",
      "Hello, I am Vj\n",
      "=============\n",
      "Hello again, Vj! How can I assist you today? If you're still interested in planning a trip or if you have something else in mind, just let me know!\n",
      "=============\n",
      "Who am I?\n",
      "=============\n",
      "You are Vj! If there’s more you’d like to share about yourself or if you have specific questions or topics in mind, feel free to let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I only know you as Vj because that's how you've introduced yourself in our conversation. I don't have any personal information about you beyond what you've shared. If there's something specific you'd like me to assist you with, just let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I know you as Vj because that's how you introduced yourself in our chat. I don't have any additional information about you unless you choose to share more. If you have any questions or topics you'd like to discuss, feel free to let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I know you as Vj simply because you told me so. I don’t have any personal information about you beyond what you've provided in this conversation. If you have any questions or topics you'd like to discuss, feel free to share!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I only know you as Vj because that's the name you've chosen to share in our conversation. I don't have any personal information about you or your background. If there's something specific you'd like to talk about or ask, just let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I know you as Vj because you've introduced yourself that way. Beyond that, I don't have any personal information about you. My knowledge about you is limited to what you choose to share in our conversation. If you have more specific questions or topics you'd like to discuss, feel free to let me know!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I know you as Vj because you've told me that in our conversation. I don't have any personal information beyond what you've shared, and I can't access any external information about you. If there's something specific you want to discuss or know, feel free to ask!\n",
      "=============\n",
      "How do you know me?\n",
      "=============\n",
      "I know you as Vj because that’s how you introduced yourself in our conversation. I don’t have any additional information about you unless you've provided it. If you have specific questions or topics in mind, I’m here to help!\n",
      "=============\n",
      "My last quesiton\n",
      "=============\n",
      "I understand—what's your last question? I'm here to help!\n",
      "=============\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T07:49:39.803544500Z",
     "start_time": "2026-02-19T07:49:39.325904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "msg2 = {\"messages\": [HumanMessage(content=\"My last quesiton\")]}\n",
    "async for event in gr.astream_events(msg2, config=mem_config, version=\"v2\"):\n"
   ],
   "id": "ea172276dfe403b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The SqliteSaver does not support async methods. Consider using AsyncSqliteSaver instead.\nfrom langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\nNote: AsyncSqliteSaver requires the aiosqlite package to use.\nInstall with:\n`pip install aiosqlite`\nSee https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.sqlite.aio.AsyncSqliteSaverfor more information.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotImplementedError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m msg2 = {\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: [HumanMessage(content=\u001B[33m\"\u001B[39m\u001B[33mMy last quesiton\u001B[39m\u001B[33m\"\u001B[39m)]}\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m gr.astream_events(msg2, config=mem_config, version=\u001B[33m\"\u001B[39m\u001B[33mv2\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m      3\u001B[39m      \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mNode: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent[\u001B[33m'\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m'\u001B[39m].get(\u001B[33m'\u001B[39m\u001B[33mlanggraph_node\u001B[39m\u001B[33m'\u001B[39m,\u001B[33m'\u001B[39m\u001B[33m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. Type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent[\u001B[33m'\u001B[39m\u001B[33mevent\u001B[39m\u001B[33m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. Name: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent[\u001B[33m'\u001B[39m\u001B[33mname\u001B[39m\u001B[33m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Projects\\personal\\langchain_prac\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1516\u001B[39m, in \u001B[36mRunnable.astream_events\u001B[39m\u001B[34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001B[39m\n\u001B[32m   1513\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(msg)\n\u001B[32m   1515\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mwith\u001B[39;00m aclosing(event_stream):\n\u001B[32m-> \u001B[39m\u001B[32m1516\u001B[39m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m event_stream:\n\u001B[32m   1517\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m event\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Projects\\personal\\langchain_prac\\.venv\\Lib\\site-packages\\langchain_core\\tracers\\event_stream.py:1100\u001B[39m, in \u001B[36m_astream_events_implementation_v2\u001B[39m\u001B[34m(runnable, value, config, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001B[39m\n\u001B[32m   1098\u001B[39m \u001B[38;5;66;03m# Await it anyway, to run any cleanup code, and propagate any exceptions\u001B[39;00m\n\u001B[32m   1099\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m contextlib.suppress(asyncio.CancelledError):\n\u001B[32m-> \u001B[39m\u001B[32m1100\u001B[39m     \u001B[38;5;28;01mawait\u001B[39;00m task\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Projects\\personal\\langchain_prac\\.venv\\Lib\\site-packages\\langchain_core\\tracers\\event_stream.py:1055\u001B[39m, in \u001B[36m_astream_events_implementation_v2.<locals>.consume_astream\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m   1052\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1053\u001B[39m     \u001B[38;5;66;03m# if astream also calls tap_output_aiter this will be a no-op\u001B[39;00m\n\u001B[32m   1054\u001B[39m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mwith\u001B[39;00m aclosing(runnable.astream(value, config, **kwargs)) \u001B[38;5;28;01mas\u001B[39;00m stream:\n\u001B[32m-> \u001B[39m\u001B[32m1055\u001B[39m         \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m event_streamer.tap_output_aiter(run_id, stream):\n\u001B[32m   1056\u001B[39m             \u001B[38;5;66;03m# All the content will be picked up\u001B[39;00m\n\u001B[32m   1057\u001B[39m             \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m   1058\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Projects\\personal\\langchain_prac\\.venv\\Lib\\site-packages\\langchain_core\\tracers\\event_stream.py:199\u001B[39m, in \u001B[36m_AstreamEventsCallbackHandler.tap_output_aiter\u001B[39m\u001B[34m(self, run_id, output)\u001B[39m\n\u001B[32m    197\u001B[39m tap = \u001B[38;5;28mself\u001B[39m.is_tapped.setdefault(run_id, sentinel)\n\u001B[32m    198\u001B[39m \u001B[38;5;66;03m# wait for first chunk\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m199\u001B[39m first = \u001B[38;5;28;01mawait\u001B[39;00m anext(output, sentinel)\n\u001B[32m    200\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m first \u001B[38;5;129;01mis\u001B[39;00m sentinel:\n\u001B[32m    201\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Projects\\personal\\langchain_prac\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2891\u001B[39m, in \u001B[36mPregel.astream\u001B[39m\u001B[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001B[39m\n\u001B[32m   2888\u001B[39m runtime = parent_runtime.merge(runtime)\n\u001B[32m   2889\u001B[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001B[32m-> \u001B[39m\u001B[32m2891\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mwith\u001B[39;00m AsyncPregelLoop(\n\u001B[32m   2892\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   2893\u001B[39m     stream=StreamProtocol(stream.put_nowait, stream_modes),\n\u001B[32m   2894\u001B[39m     config=config,\n\u001B[32m   2895\u001B[39m     store=store,\n\u001B[32m   2896\u001B[39m     cache=cache,\n\u001B[32m   2897\u001B[39m     checkpointer=checkpointer,\n\u001B[32m   2898\u001B[39m     nodes=\u001B[38;5;28mself\u001B[39m.nodes,\n\u001B[32m   2899\u001B[39m     specs=\u001B[38;5;28mself\u001B[39m.channels,\n\u001B[32m   2900\u001B[39m     output_keys=output_keys,\n\u001B[32m   2901\u001B[39m     input_keys=\u001B[38;5;28mself\u001B[39m.input_channels,\n\u001B[32m   2902\u001B[39m     stream_keys=\u001B[38;5;28mself\u001B[39m.stream_channels_asis,\n\u001B[32m   2903\u001B[39m     interrupt_before=interrupt_before_,\n\u001B[32m   2904\u001B[39m     interrupt_after=interrupt_after_,\n\u001B[32m   2905\u001B[39m     manager=run_manager,\n\u001B[32m   2906\u001B[39m     durability=durability_,\n\u001B[32m   2907\u001B[39m     trigger_to_nodes=\u001B[38;5;28mself\u001B[39m.trigger_to_nodes,\n\u001B[32m   2908\u001B[39m     migrate_checkpoint=\u001B[38;5;28mself\u001B[39m._migrate_checkpoint,\n\u001B[32m   2909\u001B[39m     retry_policy=\u001B[38;5;28mself\u001B[39m.retry_policy,\n\u001B[32m   2910\u001B[39m     cache_policy=\u001B[38;5;28mself\u001B[39m.cache_policy,\n\u001B[32m   2911\u001B[39m ) \u001B[38;5;28;01mas\u001B[39;00m loop:\n\u001B[32m   2912\u001B[39m     \u001B[38;5;66;03m# create runner\u001B[39;00m\n\u001B[32m   2913\u001B[39m     runner = PregelRunner(\n\u001B[32m   2914\u001B[39m         submit=config[CONF].get(\n\u001B[32m   2915\u001B[39m             CONFIG_KEY_RUNNER_SUBMIT, weakref.WeakMethod(loop.submit)\n\u001B[32m   (...)\u001B[39m\u001B[32m   2919\u001B[39m         node_finished=config[CONF].get(CONFIG_KEY_NODE_FINISHED),\n\u001B[32m   2920\u001B[39m     )\n\u001B[32m   2921\u001B[39m     \u001B[38;5;66;03m# enable subgraph streaming\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Projects\\personal\\langchain_prac\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:1264\u001B[39m, in \u001B[36mAsyncPregelLoop.__aenter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1262\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__aenter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> Self:\n\u001B[32m   1263\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.checkpointer:\n\u001B[32m-> \u001B[39m\u001B[32m1264\u001B[39m         saved = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.checkpointer.aget_tuple(\u001B[38;5;28mself\u001B[39m.checkpoint_config)\n\u001B[32m   1265\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1266\u001B[39m         saved = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Projects\\personal\\langchain_prac\\.venv\\Lib\\site-packages\\langgraph\\checkpoint\\sqlite\\__init__.py:503\u001B[39m, in \u001B[36mSqliteSaver.aget_tuple\u001B[39m\u001B[34m(self, config)\u001B[39m\n\u001B[32m    496\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34maget_tuple\u001B[39m(\u001B[38;5;28mself\u001B[39m, config: RunnableConfig) -> CheckpointTuple | \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    497\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Get a checkpoint tuple from the database asynchronously.\u001B[39;00m\n\u001B[32m    498\u001B[39m \n\u001B[32m    499\u001B[39m \u001B[33;03m    Note:\u001B[39;00m\n\u001B[32m    500\u001B[39m \u001B[33;03m        This async method is not supported by the SqliteSaver class.\u001B[39;00m\n\u001B[32m    501\u001B[39m \u001B[33;03m        Use get_tuple() instead, or consider using [AsyncSqliteSaver][langgraph.checkpoint.sqlite.aio.AsyncSqliteSaver].\u001B[39;00m\n\u001B[32m    502\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m503\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(_AIO_ERROR_MSG)\n",
      "\u001B[31mNotImplementedError\u001B[39m: The SqliteSaver does not support async methods. Consider using AsyncSqliteSaver instead.\nfrom langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\nNote: AsyncSqliteSaver requires the aiosqlite package to use.\nInstall with:\n`pip install aiosqlite`\nSee https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.sqlite.aio.AsyncSqliteSaverfor more information."
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
